{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are they bots?\n",
    "The company that you are working for asked you to perform a sentiment analysis using a dataset with tweets. First of all, you need to do some cleaning and extract some information.\n",
    "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: @robot3!, @robot5& and @robot7#\n",
    "\n",
    "To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the .findall() method.\n",
    "\n",
    "You write down some helpful metacharacters to help you later:\n",
    "\n",
    "\\d: digit\n",
    "\n",
    "\\w: word character\n",
    "\n",
    "\\W: non-word character\n",
    "\n",
    "\\s: whitespace\n",
    "\n",
    "The text of one tweet was saved in the variable sentiment_analysis. You can use print(sentiment_analysis) to view it in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9', '@robot4', '@robot9', '@robot7']\n"
     ]
    }
   ],
   "source": [
    "regex = re.findall(r\"@robot\\d\",sentiment_analysis)\n",
    "print(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "regex = re.findall(r\"@robot\\d\\D\",sentiment_analysis)\n",
    "print(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "regex = re.findall(r\"@robot\\d\\W\",sentiment_analysis)\n",
    "print(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the numbers\n",
    "While examining the tweet text in your dataset, you detect that some tweets carry more information. The text contains the number of retweets, user mentions, and likes. You decide to extract this important information that is given as in this example:\n",
    "\n",
    "Agh,snow! User_mentions:9, likes: 5, number of retweets: 4\n",
    "\n",
    "You pull a list of metacharacters:\\d digit,\\w word character,\\s whitespace.\n",
    "\n",
    "Always indicate whitespace with metacharacters.\n",
    "\n",
    "The variable sentiment_analysis containing the text of one tweet and the re module were loaded in your session. You can use print() to view it in the IPython Shell.\n",
    "\n",
    "Instructions 3/3\n",
    "30 XP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis=\"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "sentiment_analysis=\"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to obtain number of retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"number of retweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match and split\n",
    "Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation. You print some of these tweets to understand which pattern you need to match.\n",
    "\n",
    "You notice that the sentences are always separated by a special character, followed by a number, the word break, and after that, another special character, e.g &4break!. The words are always separated by a special character, the word new, and a normal random character, e.g #newH.\n",
    "\n",
    "The variable sentiment_analysis containing the text of one tweet, as well as the re module were already loaded in your session. You can use print(sentiment_analysis) to view it in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_sentence = r\"\\W\\dbreak\\W\" # matching [&4break!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He#newHis%newTin love with$newPscrappy.  He is&newYmissing him@newLalready'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is in love with scrappy.  He is missing him already\n"
     ]
    }
   ],
   "source": [
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, \" \", sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything clean\n",
    "Back to your Twitter sentiment analysis project! There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions.\n",
    "\n",
    "In order to clean the tweets, you want to extract some examples first. You know that most of the times links start with http and do not contain any whitespace, e.g. https://www.datacamp.com. User mentions start with @ and can have letters and numbers only, e.g. @johnsmith3.\n",
    "\n",
    "You write down some helpful quantifiers to help you: * zero or more times, + once or more, ? zero or once.\n",
    "\n",
    "The list sentiment_analysis containing the text of three tweet are already loaded in your session. You can use print() to view the data in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",'im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york'\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\n",
       " \"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",\n",
       " 'im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sentiment_analysis=pd.Series(lst,index=[545,546,547])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545    Boredd. Colddd @blueKnight39 Internet keeps st...\n",
       "546    I had a horrible nightmare last night @anitaLo...\n",
       "547    im lonely  keep me company @YourBestCompany! @...\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39 ']\n",
      "[]\n",
      "['@anitaLopez98 ', '@MyredHat31 ']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany!', '@foxRadio ']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "# Write regex to match http links and print out result\n",
    "    print(re.findall(r\"https?://\\w{3,}\\W\\w+\\W\\w+\", tweet))\n",
    "\n",
    "    # Write regex to match user mentions and print out result\n",
    "    print(re.findall(r\"@\\w+\\W?\\d{0,2}?\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datacamp solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "[]\n",
      "['@anitaLopez98', '@MyredHat31']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany!', '@foxRadio']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Write regex to match http links and print out result\n",
    "    print(re.findall(r\"https?://\\w{3,}\\W\\w+\\W\\w+\", tweet))\n",
    "\n",
    "    # Write regex to match user mentions and print out result\n",
    "    print(re.findall(r\"@\\w+\\S?\\d{0,2}?\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some time ago\n",
    "You are interested in knowing when the tweets were posted. After reading a little bit more, you learn that dates are provided in different ways. You decide to extract the dates using .findall() so you can normalize them afterwards to make them all look the same.\n",
    "\n",
    "You realize that the dates are always presented in one of the following ways:\n",
    "\n",
    "27 minutes ago\n",
    "\n",
    "4 hours ago\n",
    "\n",
    "23rd june 2018\n",
    "\n",
    "1st september 2019 17:25\n",
    "\n",
    "The list sentiment_analysis containing the text of three tweets, as well as the re module are already loaded in your session. You can use print() to view the data in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['I would like to apologize for the repeated Video Games Live related tweets. 32 minutes ago'\n",
    ",'@zaydia but i cant figure out how to get there / back / pay for a hotel 1st May 2019'\n",
    ",'FML: So much for seniority, bc of technological ineptness 23rd June 2018 17:54'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232    I would like to apologize for the repeated Vid...\n",
       "233    @zaydia but i cant figure out how to get there...\n",
       "234    FML: So much for seniority, bc of technologica...\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis=pd.Series(lst,index=[232,233,234])\n",
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w{2}\\s\\w{3,4}\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w{3,4}\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32 minutes ago']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "#27 minutes ago or 4 hours ago.\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\s\\w+\\sago\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "#23rd june 2018\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w{3,4}\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['23rd June 2018 17:54']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "#1st september 2019 17:25.\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w{,15}\\s\\d{4}\\s\\d{,2}:\\d{,2}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['23rd June 2018 17:54']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "\tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tokens\n",
    "Your next step is to tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens.\n",
    "\n",
    "You bring your list of quantifiers to help you: * zero or more times, + once or more, ? zero or once, {n, m} minimum n, maximum m.\n",
    "\n",
    "The variable sentiment_analysis containing the text of one tweet as well as the re module are already loaded in your session. You can use print(sentiment_analysis) to view it in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis='ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#MissYou', '#SoMuch', '#Friendship', '#Forever']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(regex,sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex,' ', sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ITS NOT ENOUGH TO SAY THAT IMISS U        '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metacharacters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding files\n",
    "You are not satisfied with your tweets dataset cleaning. There are still extra strings that do not provide any sentiment. Among them are strings that refer to text file names.\n",
    "\n",
    "You also find a way to detect them:\n",
    "\n",
    "They appear at the start of the string.\n",
    "They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u).\n",
    "They always finish with the txt ending.\n",
    "You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset.\n",
    "\n",
    "You write down some metacharacters to help you: ^ anchor to beginning, . any character.\n",
    "\n",
    "The variable sentiment_analysis containing the text of two tweets as well as the re module are already loaded in your session. You can use print() to view it in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780    AIshadowhunters.txt aaaaand back to my literat...\n",
       "781    ouMYTAXES.txt I am worried that I won't get my...\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis=pd.Series(lst,index=[780,781])\n",
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match text file name eg: aemyfile.txt\n",
    "regex = re.findall(r\"[a-z]{8}\\.txt\",'aemyfile.txt is the file I wanted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aemyfile.txt']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dowhunters.txt']\n",
      "['ouMYTAXES.txt']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"[A-Za-z]{,10}\\.txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIshadowhunters.txt']\n",
      " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
      "['ouMYTAXES.txt']\n",
      " I am worried that I won't get my $900 even though I paid tax last year\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"^[aeiouAEIOU]{2,3}.+txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))\n",
    "    \n",
    "\t# Replace all matches with empty string\n",
    "\tprint(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give me your email\n",
    "A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.\n",
    "The company puts some rules in place to verify that the given email address is valid:\n",
    "\n",
    "The first part can contain:\n",
    "Upper A-Z and lowercase letters a-z\n",
    "Numbers\n",
    "Characters: !, #, %, &, *, $, .\n",
    "Must have @\n",
    "Domain:\n",
    "Can contain any word characters\n",
    "But only .com ending is allowed\n",
    "The project consist of writing a script that checks if the email address follow the correct pattern. Your colleague gave you a list of email addresses as examples to test.\n",
    "\n",
    "The list emails as well as the re module are loaded in your session. You can use print(emails) to view the emails in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails=['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "  \t# Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "      \tprint(\"The email {email_example} is invalid\".format(email_example=example))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalid password\n",
    "The second part of the website project is to write a script that validates the password entered by the user. The company also puts some rules in order to verify valid passwords:\n",
    "\n",
    "It can contain lowercase a-z and uppercase letters A-Z\n",
    "\n",
    "It can contain numbers\n",
    "\n",
    "It can contain the symbols: *, #, $, %, !, &, .\n",
    "\n",
    "It must be at least 8 characters long but not more than 20\n",
    "\n",
    "Your colleague also gave you a list of passwords as examples to test.\n",
    "\n",
    "The list passwords and the module re are loaded in your session. You can use print(passwords) to view them in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords=['Apple34!rose', 'My87hou#4$', 'abc123']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]{8,20}\" \n",
    "\n",
    "for example in passwords:\n",
    "  \t# Scan the strings to find a match\n",
    "    if re.search(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
